@article{berger23,
  title = {Ethnographie et Visual Studies: {{Apports}} Des Théories de l’image Aux Pratiques d’observation et de Description},
  shorttitle = {Ethnographie et Visual Studies},
  author = {Berger, Mathieu},
  date = {2023-12-14},
  journaltitle = {SociologieS},
  shortjournal = {sociologies},
  issn = {1992-2655},
  doi = {10.4000/sociologies.21889},
  url = {http://journals.openedition.org/sociologies/21889},
  urldate = {2025-03-26},
  file = {/home/etienne_prx/Zotero/storage/UH38ATFJ/Berger - 2023 - Ethnographie et visual studies Apports des théories de l’image aux pratiques d’observation et de de.pdf}
}

@inproceedings{buolamwini_gebru18a,
  title = {Gender {{Shades}}: {{Intersectional Accuracy Disparities}} in {{Commercial Gender Classification}}},
  shorttitle = {Gender {{Shades}}},
  booktitle = {Proceedings of the 1st {{Conference}} on {{Fairness}}, {{Accountability}} and {{Transparency}}},
  author = {Buolamwini, Joy and Gebru, Timnit},
  date = {2018-01-21},
  pages = {77--91},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v81/buolamwini18a.html},
  urldate = {2025-03-27},
  abstract = {Recent studies demonstrate that machine learning algorithms can discriminate based on classes like race and gender. In this work, we present an approach to evaluate bias present in automated facial analysis algorithms and datasets with respect to phenotypic subgroups. Using the dermatologist  approved Fitzpatrick Skin Type classification system, we characterize the gender and skin type distribution of two facial analysis benchmarks, IJB-A and Adience. We find that these datasets are overwhelmingly composed of lighter-skinned subjects (79.6\% for IJB-A and 86.2\% for Adience) and introduce a new facial analysis dataset which is balanced by gender and skin type. We evaluate 3 commercial gender classification systems using our dataset and show that darker-skinned females are the most misclassified group (with error rates of up to 34.7\%). The maximum error rate for lighter-skinned males is 0.8\%. The substantial disparities in the accuracy of classifying darker females, lighter females, darker males, and lighter males in gender classification systems require urgent attention if commercial companies are to build genuinely fair, transparent and accountable facial analysis algorithms.},
  eventtitle = {Conference on {{Fairness}}, {{Accountability}} and {{Transparency}}},
  langid = {english},
  file = {/home/etienne_prx/Zotero/storage/279IB3QU/Buolamwini and Gebru - 2018 - Gender Shades Intersectional Accuracy Disparities in Commercial Gender Classification.pdf;/home/etienne_prx/Zotero/storage/KIMXGK5T/Buolamwini and Gebru - 2018 - Gender Shades Intersectional Accuracy Disparities in Commercial Gender Classification.pdf}
}

@article{chauvin_reix15,
  title = {Sociologies visuelles. Histoire et pistes de recherche},
  author = {Chauvin, Pierre-Marie and Reix, Fabien},
  date = {2015-05-22},
  journaltitle = {L'Année sociologique},
  volume = {65},
  number = {1},
  pages = {15--41},
  publisher = {Presses Universitaires de France},
  issn = {0066-2399},
  doi = {10.3917/anso.151.0015},
  url = {https://shs.cairn.info/revue-l-annee-sociologique-2015-1-page-15},
  urldate = {2025-03-26},
  langid = {french},
  file = {/home/etienne_prx/Zotero/storage/3TWMWTHB/Chauvin and Reix - 2015 - Sociologies visuelles. Histoire et pistes de recherche.pdf}
}

@article{chen_etal23,
  title = {Using Social Media Images as Data in Social Science Research},
  author = {Chen, Yan and Sherren, Kate and Smit, Michael and Lee, Kyung Young},
  date = {2023-04-01},
  journaltitle = {New Media \& Society},
  volume = {25},
  number = {4},
  pages = {849--871},
  publisher = {SAGE Publications},
  issn = {1461-4448},
  doi = {10.1177/14614448211038761},
  url = {https://doi.org/10.1177/14614448211038761},
  urldate = {2025-03-16},
  abstract = {We conducted a scoping review to identify and describe trends in the use of social media images as data sources to inform social science research in published articles from 2015 to 2019. The identified trends include the following: (1) there is increasing interest in social media images as research data, especially in disciplines like sociology, cultural studies, communication and environmental studies; (2) the photo sample size is often smaller than that is typically used in text-based social media analysis and usually is collected manually; (3) thematic coding, object recognition and narrative analysis are the most popular analysis methods that are often conducted manually; (4) computer vision and machine-learning technologies have been increasingly but still infrequently used and are not fit for all purposes; and (5) relatively few papers mention ethics and privacy issues, or apply strategies to address ethical issues. We identify noteworthy research gaps, and opportunities to address limitations and challenges.},
  langid = {english},
  file = {/home/etienne_prx/Zotero/storage/PUFXF7CI/Chen et al. - 2023 - Using social media images as data in social science research.pdf}
}

@article{cohn10a,
  title = {Advances in {{Behavioral Science Using Automated Facial Image Analysis}} and {{Synthesis}} [{{Social Sciences}}]},
  author = {Cohn, Jeffrey F.},
  date = {2010-11},
  journaltitle = {IEEE Signal Processing Magazine},
  volume = {27},
  number = {6},
  pages = {128--133},
  issn = {1558-0792},
  doi = {10.1109/MSP.2010.938102},
  url = {https://ieeexplore.ieee.org/abstract/document/5563099},
  urldate = {2025-03-16},
  abstract = {The face conveys information about a person's age, sex, background, and identity; what they are feeling, thinking, or likely to do next. Facial expression regulates face-to-face interactions, indicates reciprocity and interpersonal attraction or repulsion, and enables intersubjectivity between members of different cultures. Facial expression indexes neurological and psychiatric functioning and reveals personality and socioemotional development. Not surprisingly, the face has been of keen interest to behavioral scientists. About 15 years ago, computer scientists became increasingly interested in the use of computer vision and graphics to automatically analyze and synthesize facial expression. This effort was made possible in part by the development in psychology of detailed coding systems for describing facial actions and their relation to basic emotions, that is, emotions that are interpreted similarly in diverse cultures. The most detailed of these systems, the Facial Action Coding System (FACS), informed the development of the MPEG-4 facial animation parameters for video transmission and enabled progress toward automated measurement and synthesis of facial actions for research in affective computing, social signal processing, and behavioral science. This article reports key advances in behavioral science that are becoming possible through these developments. Before beginning, automated facial image analysis and synthesis (AFAS) is briefly described.},
  eventtitle = {{{IEEE Signal Processing Magazine}}}
}

@article{Discrimination,
  title = {Discrimination, intelligence artificielle et décisions algorithmiques},
  langid = {french},
  file = {/home/etienne_prx/Zotero/storage/HWVLRFJ8/Discrimination, intelligence artificielle et décisions algorithmiques.pdf}
}

@online{Gender,
  title = {Gender {{Shades}}},
  url = {http://gendershades.org/overview.html},
  urldate = {2025-03-16},
  file = {/home/etienne_prx/Zotero/storage/RJMU8AGH/overview.html}
}

@online{ImageNet,
  title = {{{ImageNet}}},
  url = {https://www.image-net.org/},
  urldate = {2025-03-16},
  file = {/home/etienne_prx/Zotero/storage/LN2HA598/www.image-net.org.html}
}

@article{russakovsky_etal15,
  title = {{{ImageNet Large Scale Visual Recognition Challenge}}},
  author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
  date = {2015-12-01},
  journaltitle = {International Journal of Computer Vision},
  shortjournal = {Int J Comput Vis},
  volume = {115},
  number = {3},
  pages = {211--252},
  issn = {1573-1405},
  doi = {10.1007/s11263-015-0816-y},
  url = {https://doi.org/10.1007/s11263-015-0816-y},
  urldate = {2025-03-16},
  abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5~years of the challenge, and propose future directions and improvements.},
  langid = {english},
  file = {/home/etienne_prx/Zotero/storage/HJX26DFR/Russakovsky et al. - 2015 - ImageNet Large Scale Visual Recognition Challenge.pdf}
}

@article{slavkova17,
  title = {Œuvre, expérience visuelle, « tournant pictorial ». Débats méthodologiques sur les approches de l’image},
  author = {Slavkova, Iveta},
  date = {2017-10-01},
  journaltitle = {Histoire Politique},
  shortjournal = {histoirepolitique},
  number = {33},
  issn = {1954-3670},
  doi = {10.4000/histoirepolitique.9809},
  url = {http://journals.openedition.org/histoirepolitique/9809},
  urldate = {2025-03-26},
  langid = {french},
  file = {/home/etienne_prx/Zotero/storage/CXSZTBMT/Slavkova - 2017 - Œuvre, expérience visuelle, « tournant pictorial ». Débats méthodologiques sur les approches de l’im.pdf}
}

@article{tissier-desbordes04,
  title = {L’analyse de visuels : Pour une complémentarité des principales approches},
  shorttitle = {L’analyse de visuels},
  author = {Tissier-Desbordes, Élisabeth},
  date = {2004},
  journaltitle = {Décisions Marketing},
  volume = {36},
  number = {4},
  pages = {63--74},
  publisher = {EMS Éditions},
  issn = {0779-7389},
  doi = {10.3917/dm.036.0063},
  url = {https://shs.cairn.info/article/DM_036_0063},
  urldate = {2025-03-26},
  langid = {french},
  file = {/home/etienne_prx/Zotero/storage/KBTIJ7UG/Tissier-Desbordes - 2004 - L’analyse de visuels  Pour une complémentarité des principales approches.pdf}
}

@article{wang_kosinski18,
  title = {Deep Neural Networks Are More Accurate than Humans at Detecting Sexual Orientation from Facial Images},
  author = {Wang, Yilun and Kosinski, Michal},
  date = {2018},
  journaltitle = {Journal of Personality and Social Psychology},
  volume = {114},
  number = {2},
  pages = {246--257},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-1315},
  doi = {10.1037/pspa0000098},
  abstract = {We show that faces contain much more information about sexual orientation than can be perceived or interpreted by the human brain. We used deep neural networks to extract features from 35,326 facial images. These features were entered into a logistic regression aimed at classifying sexual orientation. Given a single facial image, a classifier could correctly distinguish between gay and heterosexual men in 81\% of cases, and in 71\% of cases for women. Human judges achieved much lower accuracy: 61\% for men and 54\% for women. The accuracy of the algorithm increased to 91\% and 83\%, respectively, given five facial images per person. Facial features employed by the classifier included both fixed (e.g., nose shape) and transient facial features (e.g., grooming style). Consistent with the prenatal hormone theory of sexual orientation, gay men and women tended to have gender-atypical facial morphology, expression, and grooming styles. Prediction models aimed at gender alone allowed for detecting gay males with 57\% accuracy and gay females with 58\% accuracy. Those findings advance our understanding of the origins of sexual orientation and the limits of human perception. Additionally, given that companies and governments are increasingly using computer vision algorithms to detect people’s intimate traits, our findings expose a threat to the privacy and safety of gay men and women. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  file = {/home/etienne_prx/Zotero/storage/9VBJBUGC/2018-03783-002.html}
}

@article{williams_etal20,
  title = {Images as {{Data}} for {{Social Science Research}}: {{An Introduction}} to {{Convolutional Neural Nets}} for {{Image Classification}}},
  shorttitle = {Images as {{Data}} for {{Social Science Research}}},
  author = {Williams, Nora Webb and Casas, Andreu and Wilkerson, John D.},
  date = {2020-07},
  journaltitle = {Elements in Quantitative and Computational Methods for the Social Sciences},
  publisher = {Cambridge University Press},
  doi = {10.1017/9781108860741},
  url = {https://www.cambridge.org/core/elements/images-as-data-for-social-science-research/0376EE8A7A21F5B47FC4EC24DF07EFE9},
  urldate = {2025-03-16},
  abstract = {Cambridge Core - Research Methods in Politics - Images as Data for Social Science Research},
  isbn = {9781108860741 9781108816854},
  langid = {english},
  file = {/home/etienne_prx/Zotero/storage/9P3PIEFY/Williams et al. - 2020 - Images as Data for Social Science Research An Introduction to Convolutional Neural Nets for Image C.pdf}
}

@article{zhang_peng24,
  title = {Image {{Clustering}}: {{An Unsupervised Approach}} to {{Categorize Visual Data}} in {{Social Science Research}}},
  shorttitle = {Image {{Clustering}}},
  author = {Zhang, Han and Peng, Yilang},
  date = {2024-08-01},
  journaltitle = {Sociological Methods \& Research},
  volume = {53},
  number = {3},
  pages = {1534--1587},
  publisher = {SAGE Publications Inc},
  issn = {0049-1241},
  doi = {10.1177/00491241221082603},
  url = {https://doi.org/10.1177/00491241221082603},
  urldate = {2025-03-16},
  abstract = {Automated image analysis has received increasing attention in social scientific research, yet existing scholarship has mostly covered the application of supervised learning to classify images into predefined categories. This study focuses on the task of unsupervised image clustering, which aims to automatically discover categories from unlabelled image data. We first review the steps to perform image clustering and then focus on one key challenge in this task—finding intermediate representations of images. We present several methods of extracting intermediate image representations, including the bag-of-visual-words model, self-supervised learning, and transfer learning (in particular, feature extraction with pretrained models). We compare these methods using various visual datasets, including images related to protests in China from Weibo, images about climate change on Instagram, and profile images of the Russian Internet Research Agency on Twitter. In addition, we propose a systematic way to interpret and validate clustering solutions. Results show that transfer learning significantly outperforms the other methods. The dataset used in the pretrained model critically determines what categories the algorithms can discover.},
  langid = {english},
  file = {/home/etienne_prx/Zotero/storage/9H8XEA63/Zhang and Peng - 2024 - Image Clustering An Unsupervised Approach to Categorize Visual Data in Social Science Research.pdf}
}
